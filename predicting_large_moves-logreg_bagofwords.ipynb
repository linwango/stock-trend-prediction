{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:30:52.366956Z",
     "start_time": "2020-11-19T00:30:51.170211Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:30:53.566745Z",
     "start_time": "2020-11-19T00:30:52.371528Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:30:53.572203Z",
     "start_time": "2020-11-19T00:30:53.569213Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED=229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:30:53.577934Z",
     "start_time": "2020-11-19T00:30:53.574865Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:30:53.601180Z",
     "start_time": "2020-11-19T00:30:53.580781Z"
    },
    "code_folding": [
     0,
     9
    ]
   },
   "outputs": [],
   "source": [
    "class Raw_Dataset:\n",
    "    def __init__(self, tweet_file_path, nasdaq_file_path):\n",
    "        self.tweet = Raw_Dataset.__read_tweet_dataset(tweet_file_path)\n",
    "        self.nasdaq = Raw_Dataset.__read_nasdaq_dataset(nasdaq_file_path)\n",
    "        self.data_df = self.__combine_data()\n",
    "        self.train_val_df, self.test_df = self.__split_train_test()\n",
    "        self.reweighted_train_val_df = self.__re_weighting()\n",
    "\n",
    "    @staticmethod\n",
    "    def __read_tweet_dataset(tweet_file_path):\n",
    "        tweet = pd.read_csv(tweet_file_path)[['date', 'content']]\n",
    "        tweet['date'] = pd.to_datetime(tweet['date'])\n",
    "        tweet = tweet[tweet['date'] >= '2016-11-09'].reset_index(drop=True)\n",
    "        return tweet\n",
    "    \n",
    "    @staticmethod\n",
    "    def __read_nasdaq_dataset(nasdaq_file_path):\n",
    "        nasdaq = pd.read_csv(nasdaq_file_path)[['Date', 'Close']]\n",
    "        nasdaq['Date'] = pd.to_datetime(nasdaq['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        nasdaq['Tweet_Start_Date'], nasdaq['Tweet_End_Date'] = np.NaN, np.NaN\n",
    "        nasdaq['Return'], nasdaq['Return_Bucket'] = np.NaN, np.NaN\n",
    "        for i, row in nasdaq.iterrows():\n",
    "            if i - 1 < 0:\n",
    "                continue\n",
    "            nasdaq.loc[i, 'Tweet_Start_Date'] = nasdaq.iloc[i - 1]['Date']\n",
    "            nasdaq.loc[i, 'Tweet_End_Date'] = nasdaq.iloc[i]['Date']\n",
    "            ret = math.log(nasdaq.iloc[i]['Close'] / nasdaq.iloc[i - 1]['Close'])\n",
    "            nasdaq.loc[i, 'Return'] = ret\n",
    "            nasdaq.loc[i, 'Return_Bucket'] = 1 if abs(ret) > 0.01 else 0\n",
    "\n",
    "        return nasdaq.iloc[1:]\n",
    "\n",
    "    def __combine_data(self):\n",
    "        tweet, nasdaq = self.tweet, self.nasdaq\n",
    "        result = pd.DataFrame(columns=['date', 'content', 'nasdaq_date', 'return', 'return_bucket'])\n",
    "        for i, row in nasdaq.iterrows():\n",
    "            tweet_filtered = tweet[(tweet['date'] >= row['Tweet_Start_Date']) & \\\n",
    "                                   (tweet['date'] < row['Tweet_End_Date'])]\n",
    "            tweet_filtered = tweet_filtered[tweet_filtered['content'].apply(lambda x: len(x.split(' '))) >= 5] \n",
    "            tweet_filtered['nasdaq_date'] = row['Tweet_End_Date']\n",
    "            tweet_filtered['return'] = row['Return']\n",
    "            tweet_filtered['return_bucket'] = row['Return_Bucket']\n",
    "            tweet_filtered = tweet_filtered[['date', 'content', 'nasdaq_date', 'return', 'return_bucket']]\n",
    "            result = result.append(tweet_filtered, ignore_index = True)\n",
    "        return result\n",
    "\n",
    "    def __split_train_test(self):\n",
    "        data_df = self.data_df\n",
    "        train_val_df, test_df, _, _ = train_test_split(data_df, data_df['return_bucket'], test_size=0.20, random_state=SEED)\n",
    "        print(f\"Dataset Shape --- data_df {data_df.shape}, train_val_df {train_val_df.shape}, test_df {test_df.shape}\")\n",
    "        return train_val_df.reset_index(), test_df.reset_index()\n",
    "\n",
    "    def __re_weighting(self):\n",
    "        train_val_df = self.train_val_df\n",
    "        ratio = len(train_val_df[train_val_df['return_bucket'] == 0]) // len(train_val_df[train_val_df['return_bucket'] == 1])\n",
    "        if ratio < 1:\n",
    "            return\n",
    "\n",
    "        reweighted_train_val_df = train_val_df[train_val_df['return_bucket'] == 0]\n",
    "        for i in range(ratio):\n",
    "            reweighted_train_val_df = reweighted_train_val_df.append(train_val_df[train_val_df['return_bucket'] == 1])\n",
    "        print(f'Reweighted Dataset Shape --- reweighted_ratio: {ratio}, reweighted_train_df: {reweighted_train_val_df.shape}')\n",
    "        return reweighted_train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:04.826846Z",
     "start_time": "2020-11-19T00:30:53.603894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape --- data_df (11227, 5), train_val_df (8981, 5), test_df (2246, 5)\n",
      "Reweighted Dataset Shape --- reweighted_ratio: 2, reweighted_train_df: (11814, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>nasdaq_date</th>\n",
       "      <th>return</th>\n",
       "      <th>return_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-09 05:36:58</td>\n",
       "      <td>Such a beautiful and important evening! The fo...</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-10 13:31:27</td>\n",
       "      <td>Happy 241st birthday to the U.S. Marine Corps!...</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-10 20:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-10 20:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-11 05:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>-0.003579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                            content  \\\n",
       "0 2016-11-09 05:36:58  Such a beautiful and important evening! The fo...   \n",
       "1 2016-11-10 13:31:27  Happy 241st birthday to the U.S. Marine Corps!...   \n",
       "2 2016-11-10 20:10:46  A fantastic day in D.C. Met with President Oba...   \n",
       "3 2016-11-10 20:19:44  Just had a very open and successful presidenti...   \n",
       "4 2016-11-11 05:14:20  Love the fact that the small groups of protest...   \n",
       "\n",
       "  nasdaq_date    return  return_bucket  \n",
       "0  2016-11-10 -0.008082            0.0  \n",
       "1  2016-11-11  0.005420            0.0  \n",
       "2  2016-11-11  0.005420            0.0  \n",
       "3  2016-11-11  0.005420            0.0  \n",
       "4  2016-11-14 -0.003579            0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = Raw_Dataset(tweet_file_path='realdonaldtrump.csv', nasdaq_file_path='^IXIC.csv')\n",
    "raw_dataset.data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T01:37:13.519105Z",
     "start_time": "2020-10-22T01:37:13.454136Z"
    }
   },
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:04.884795Z",
     "start_time": "2020-11-19T00:31:04.847164Z"
    },
    "code_folding": [
     0,
     1,
     9,
     15,
     32,
     41,
     48,
     52
    ]
   },
   "outputs": [],
   "source": [
    "class OneHot_Encoded_Dataset:\n",
    "    def __init__(self, train_df):\n",
    "        messages = train_df['content'].to_list()\n",
    "        word_count, self.word_dictionary = OneHot_Encoded_Dataset.__create_dictionary(messages)\n",
    "        train_df['text_in_array'] = train_df['content'].\\\n",
    "            apply(lambda x: OneHot_Encoded_Dataset.__transform_text(x, self.word_dictionary))\n",
    "        self.X_train, self.y_train = OneHot_Encoded_Dataset.__to_numpy(train_df)\n",
    "        self.X_test, self.y_test = None, None\n",
    "\n",
    "    def encode_test_df(self, test_df):\n",
    "        test_df['text_in_array'] = test_df['content'].\\\n",
    "            apply(lambda x: OneHot_Encoded_Dataset.__transform_text(x, self.word_dictionary))\n",
    "        self.X_test, self.y_test = OneHot_Encoded_Dataset.__to_numpy(test_df)\n",
    "\n",
    "    @staticmethod\n",
    "    def __create_dictionary(messages):\n",
    "        count = {}\n",
    "        for message in messages:\n",
    "            for word in OneHot_Encoded_Dataset.__get_words(message):\n",
    "                revised_word = OneHot_Encoded_Dataset.__revise_word(word)\n",
    "                if revised_word is not None:\n",
    "                    count[revised_word] = count.get(revised_word, 0) + 1\n",
    "\n",
    "        result, index = {}, 0\n",
    "        for revised_word in count.keys():\n",
    "            if count[revised_word] >= 5:\n",
    "                result[revised_word] = index\n",
    "                index += 1\n",
    "        print(f'One-hot Encoding Dictionary Size --- {len(result)}')\n",
    "        return count, result\n",
    "\n",
    "    @staticmethod\n",
    "    def __transform_text(message, word_dictionary):\n",
    "        result = np.zeros(len(word_dictionary))\n",
    "        for word in OneHot_Encoded_Dataset.__get_words(message):\n",
    "            revised_word = OneHot_Encoded_Dataset.__revise_word(word)\n",
    "            if revised_word is not None and revised_word in word_dictionary:\n",
    "                result[word_dictionary[revised_word]] += 1\n",
    "        return list(result)\n",
    "\n",
    "    @staticmethod\n",
    "    def __revise_word(word):\n",
    "        if 'pic.twitter.com' in word or 'http' in word:\n",
    "            return None\n",
    "        word = ''.join(e for e in word if e.isalnum())\n",
    "        return word\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_words(message):\n",
    "        return [word.lower() for word in message.split(' ')]\n",
    "    \n",
    "    @staticmethod\n",
    "    def __to_numpy(df):\n",
    "        x, y = [], []\n",
    "        for _, row in df.iterrows():\n",
    "            x_i, y_i = list(row['text_in_array']), row['return_bucket']\n",
    "            x.append(x_i)\n",
    "            y.append(y_i)\n",
    "        return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:36.906375Z",
     "start_time": "2020-11-19T00:31:04.896528Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot Encoding Dictionary Size --- 4747\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHot_Encoded_Dataset(raw_dataset.reweighted_train_val_df)\n",
    "onehot.encode_test_df(raw_dataset.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:36.944831Z",
     "start_time": "2020-11-19T00:31:36.926421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (11814, 4747) | X_test Shape: (2246, 4747)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = onehot.X_train, onehot.y_train\n",
    "X_test, y_test = onehot.X_test, onehot.y_test\n",
    "print(f'X_train Shape: {X_train.shape} | X_test Shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:42.550994Z",
     "start_time": "2020-11-19T00:31:36.948130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty='l2')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:42.705838Z",
     "start_time": "2020-11-19T00:31:42.555188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[994 507]\n",
      " [411 334]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.66      0.68      1501\n",
      "         1.0       0.40      0.45      0.42       745\n",
      "\n",
      "    accuracy                           0.59      2246\n",
      "   macro avg       0.55      0.56      0.55      2246\n",
      "weighted avg       0.60      0.59      0.60      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test).astype(int)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:42.752340Z",
     "start_time": "2020-11-19T00:31:42.709181Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:47.401249Z",
     "start_time": "2020-11-19T00:31:42.755790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocabulary: 128304\n",
      "X_train Shape: (11814, 128304) | X_test Shape: (2246, 128304)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(raw_dataset.reweighted_train_val_df['content'])\n",
    "X_test = vectorizer.transform(raw_dataset.test_df['content'])\n",
    "print(f'Length of Vocabulary: {len(vectorizer.vocabulary_)}')\n",
    "print(f'X_train Shape: {X_train.shape} | X_test Shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:47.409879Z",
     "start_time": "2020-11-19T00:31:47.405029Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = raw_dataset.reweighted_train_val_df['return_bucket']\n",
    "y_test = raw_dataset.test_df['return_bucket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:51.059131Z",
     "start_time": "2020-11-19T00:31:47.413350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty='l2')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T00:31:51.102378Z",
     "start_time": "2020-11-19T00:31:51.064510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1210  291]\n",
      " [ 481  264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.81      0.76      1501\n",
      "         1.0       0.48      0.35      0.41       745\n",
      "\n",
      "    accuracy                           0.66      2246\n",
      "   macro avg       0.60      0.58      0.58      2246\n",
      "weighted avg       0.64      0.66      0.64      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test).astype(int)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
